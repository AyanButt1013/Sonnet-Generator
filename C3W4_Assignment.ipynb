{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFWbEb6uGbN-"
      },
      "source": [
        "# Week 4: Predicting the next word\n",
        "\n",
        "Welcome to this assignment! During this week you saw how to create a model that will predict the next word in a text sequence, now you will implement such model and train it using a corpus of Shakespeare's sonnets, while also creating some helper functions to pre-process the data.\n",
        "\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp4A-ZBwSN11"
      },
      "source": [
        "_**NOTE:** To prevent errors from the autograder, please avoid editing or deleting non-graded cells in this notebook . Please only put your solutions in between the `### START CODE HERE` and `### END CODE HERE` code comments, and also refrain from adding any new cells._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BOwsuGQQY9OL",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTxqlHqKHzhr"
      },
      "source": [
        "For this assignment you will be using the [Shakespeare Sonnets Dataset](https://www.opensourceshakespeare.org/views/sonnets/sonnet_view.php?range=viewrange&sonnetrange1=1&sonnetrange2=154), which contains more than 2000 lines of text extracted from Shakespeare's sonnets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WZ4qOUzujMP6",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a47e57-7eb5-468c-ba39-fb7b40603f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "100% 93.6k/93.6k [00:00<00:00, 99.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# sonnets.txt\n",
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Pfd-nYKij5yY",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1efbd0-1185-4566-a2b1-45b9911f70db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2159 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "from fairest creatures we desire increase,\n",
            "that thereby beauty's rose might never die,\n",
            "but as the riper should by time decease,\n",
            "his tender heir might bear his memory:\n",
            "but thou, contracted to thine own bright eyes,\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define path for file with sonnets\n",
        "SONNETS_FILE = './sonnets.txt'\n",
        "\n",
        "# Read the data\n",
        "with open('./sonnets.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imB15zrSNhA1"
      },
      "source": [
        "## Tokenizing the text\n",
        "\n",
        "Now fit the Tokenizer to the corpus and save the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AAhM_qAZk0o5",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77-0sA46OETa"
      },
      "source": [
        "When converting the text into sequences you can use the `texts_to_sequences` method as you have done throughout this course.\n",
        "\n",
        "In the next graded function you will need to process this corpus one line at a time. Given this, it is important to keep in mind that the way you are feeding the data unto this method affects the result. Check the following example to make this clearer.\n",
        "\n",
        "The first example of the corpus is a string and looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tqhPxdeXlfjh",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "80a11c44-f194-46a8-83ba-4abe649236e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from fairest creatures we desire increase,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "corpus[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFMP4z11O3os"
      },
      "source": [
        "If you pass this text directly into the `texts_to_sequences` method you will get an unexpected result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EMSEhmbzNZCE",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b1ac86-de76-4fd3-9aab-fe351f718fdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [58],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer.texts_to_sequences(corpus[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPZmZtpEPEeI"
      },
      "source": [
        "This happened because `texts_to_sequences` expects a list and you are providing a string. However a string is still and `iterable` in Python so you will get the word index of every character in the string.\n",
        "\n",
        "Instead you need to place the example whithin a list before passing it to the method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Qmgo-vXhk4nd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946ce736-8c29-4506-950c-ab32196e55a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer.texts_to_sequences([corpus[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DU7wK-eQ5dc"
      },
      "source": [
        "Notice that you received the sequence wrapped inside a list so in order to get only the desired sequence you need to explicitly get the first item in the list like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kpTy8WmIQ57P",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0dca21-4cd7-4572-e664-f665da16b896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 417, 877, 166, 213, 517]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqy9KjXRJ9A"
      },
      "source": [
        "## Generating n_grams\n",
        "\n",
        "Now complete the `n_gram_seqs` function below. This function receives the fitted tokenizer and the corpus (which is a list of strings) and should return a list containing the `n_gram` sequences for each line in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "deletable": false,
        "id": "iy4baJMDl6kj",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: n_gram_seqs\n",
        "def n_gram_seqs(corpus, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "\n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "\n",
        "    Returns:\n",
        "        input_sequences (list of int): the n-gram sequences for each line in the corpus\n",
        "    \"\"\"\n",
        "    input_sequences = []\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "\t    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\t    for i in range(1, len(token_list)):\n",
        "\t\t    n_gram_sequence = token_list[:i+1]\n",
        "\t\t    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DlKqW2pfM7G3",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e62dbd0-9737-482b-b572-4b7bbb500301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with one example\n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HL8Ug6UU0Jt"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_gram sequences for first example look like this:\n",
        "\n",
        "[[34, 417],\n",
        " [34, 417, 877],\n",
        " [34, 417, 877, 166],\n",
        " [34, 417, 877, 166, 213],\n",
        " [34, 417, 877, 166, 213, 517]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wtPpCcBjNc4c",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9bfd1a1-c069-4440-d716-f51091ae22a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156],\n",
              " [8, 878, 134, 351, 102, 156, 199],\n",
              " [16, 22],\n",
              " [16, 22, 2],\n",
              " [16, 22, 2, 879],\n",
              " [16, 22, 2, 879, 61],\n",
              " [16, 22, 2, 879, 61, 30],\n",
              " [16, 22, 2, 879, 61, 30, 48],\n",
              " [16, 22, 2, 879, 61, 30, 48, 634],\n",
              " [25, 311],\n",
              " [25, 311, 635],\n",
              " [25, 311, 635, 102],\n",
              " [25, 311, 635, 102, 200],\n",
              " [25, 311, 635, 102, 200, 25],\n",
              " [25, 311, 635, 102, 200, 25, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with a bigger corpus\n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIzecMczU9UB"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_gram sequences for next 3 examples look like this:\n",
        "\n",
        "[[8, 878],\n",
        " [8, 878, 134],\n",
        " [8, 878, 134, 351],\n",
        " [8, 878, 134, 351, 102],\n",
        " [8, 878, 134, 351, 102, 156],\n",
        " [8, 878, 134, 351, 102, 156, 199],\n",
        " [16, 22],\n",
        " [16, 22, 2],\n",
        " [16, 22, 2, 879],\n",
        " [16, 22, 2, 879, 61],\n",
        " [16, 22, 2, 879, 61, 30],\n",
        " [16, 22, 2, 879, 61, 30, 48],\n",
        " [16, 22, 2, 879, 61, 30, 48, 634],\n",
        " [25, 311],\n",
        " [25, 311, 635],\n",
        " [25, 311, 635, 102],\n",
        " [25, 311, 635, 102, 200],\n",
        " [25, 311, 635, 102, 200, 25],\n",
        " [25, 311, 635, 102, 200, 25, 278]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V_RjFWQSu"
      },
      "source": [
        "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "laMwiRUpmuSd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e6136d-3c6a-41a1-d2b5-22e58429c2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences have length: 15462\n",
            "maximum length of sequences is: 11\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OciMdmEdE9L"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_grams of input_sequences have length: 15462\n",
        "maximum length of sequences is: 11\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHY7HroqWq12"
      },
      "source": [
        "## Add padding to the sequences\n",
        "\n",
        "Now code the `pad_seqs` function which will pad any given sequences to the desired maximum length. Notice that this function receives a list of sequences and should return a numpy array with the padded sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "cellView": "code",
        "deletable": false,
        "id": "WW1-qAZaWOhC",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: pad_seqs\n",
        "def pad_seqs(input_sequences, maxlen):\n",
        "    \"\"\"\n",
        "    Pads tokenized sequences to the same length\n",
        "\n",
        "    Args:\n",
        "        input_sequences (list of int): tokenized sequences to pad\n",
        "        maxlen (int): maximum length of the token sequences\n",
        "\n",
        "    Returns:\n",
        "        padded_sequences (array of int): tokenized sequences padded to the same length\n",
        "    \"\"\"\n",
        "    ### START CODE HERE\n",
        "    padded_sequences = pad_sequences (input_sequences, maxlen = maxlen)\n",
        "\n",
        "    return padded_sequences\n",
        "    ### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IqVQ0pb3YHLr",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c605887-b176-4a54-c6d7-4d469566f545"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,  34, 417],\n",
              "       [  0,   0,   0,  34, 417, 877],\n",
              "       [  0,   0,  34, 417, 877, 166],\n",
              "       [  0,  34, 417, 877, 166, 213],\n",
              "       [ 34, 417, 877, 166, 213, 517]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, max([len(x) for x in first_example_sequence]))\n",
        "first_padded_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_avDznXRnU"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "array([[  0,   0,   0,   0,  34, 417],\n",
        "       [  0,   0,   0,  34, 417, 877],\n",
        "       [  0,   0,  34, 417, 877, 166],\n",
        "       [  0,  34, 417, 877, 166, 213],\n",
        "       [ 34, 417, 877, 166, 213, 517]], dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "j56_UCOBYzZt",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac5d6c9-7aaa-4f74-9849-b40ccd571de8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
              "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
              "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
              "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
              "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
              "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
              "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
              "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
              "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
              "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
              "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
              "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
              "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
              "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
              "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
              "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
              "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
              "       [  0,  25, 311, 635, 102, 200,  25, 278]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rmcDluOXcIU"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
        "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
        "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
        "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
        "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
        "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
        "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
        "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
        "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
        "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
        "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
        "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
        "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
        "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
        "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
        "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
        "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
        "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
        "       [  0,  25, 311, 635, 102, 200,  25, 278]], dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rgK-Q_micEYA",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5696fd51-1db9-4ba7-bf40-7bde42ac4206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (15462, 11)\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59RD1YYNc7CW"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "padded corpus has shape: (15462, 11)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOidyPrXxf7"
      },
      "source": [
        "## Split the data into features and labels\n",
        "\n",
        "Before feeding the data into the neural network you should split it into features and labels. In this case the features will be the padded n_gram sequences with the last word removed from them and the labels will be the removed word.\n",
        "\n",
        "Complete the `features_and_labels` function below. This function expects the padded n_gram sequences as input and should return a tuple containing the features and the one hot encoded labels.\n",
        "\n",
        "Notice that the function also receives the total of words in the corpus, this parameter will be very important when one hot enconding the labels since every word in the corpus will be a label at least once. If you need a refresh of how the `to_categorical` function works take a look at the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "cellView": "code",
        "deletable": false,
        "id": "9WGGbYdnZdmJ",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: features_and_labels\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    \"\"\"\n",
        "    Generates features and labels from n-grams\n",
        "\n",
        "    Args:\n",
        "        input_sequences (list of int): sequences to split features and labels from\n",
        "        total_words (int): vocabulary size\n",
        "\n",
        "    Returns:\n",
        "        features, one_hot_labels (array of int, array of int): arrays of features and one-hot encoded labels\n",
        "    \"\"\"\n",
        "    ### START CODE HERE\n",
        "    features = input_sequences[:,:-1]\n",
        "    labels = input_sequences[:,-1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return features, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "23DolaBRaIAZ",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc44ac0-38f7-4e19-c00e-c5c038f66ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (5, 3211)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,  34],\n",
              "       [  0,   0,   0,  34, 417],\n",
              "       [  0,   0,  34, 417, 877],\n",
              "       [  0,  34, 417, 877, 166],\n",
              "       [ 34, 417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with the padded n_grams_seq of the first example\n",
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t4yAx2UaQ43"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "labels have shape: (5, 3211)\n",
        "\n",
        "features look like this:\n",
        "\n",
        "array([[  0,   0,   0,   0,  34],\n",
        "       [  0,   0,   0,  34, 417],\n",
        "       [  0,   0,  34, 417, 877],\n",
        "       [  0,  34, 417, 877, 166],\n",
        "       [ 34, 417, 877, 166, 213]], dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GRTuLEt3bRKa",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aea6c8c-b10d-485a-d1c4-2bf34bf5fc88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (15462, 10)\n",
            "labels have shape: (15462, 3211)\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXSMK_HpdLns"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "features have shape: (15462, 10)\n",
        "labels have shape: (15462, 3211)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltxaOCE_aU6J"
      },
      "source": [
        "## Create the model\n",
        "\n",
        "Now you should define a model architecture capable of achieving an accuracy of at least 80%.\n",
        "\n",
        "Some hints to help you in this task:\n",
        "\n",
        "- An appropriate `output_dim` for the first layer (Embedding) is 100, this is already provided for you.\n",
        "- A Bidirectional LSTM is helpful for this particular problem.\n",
        "- The last layer should have the same number of units as the total number of words in the corpus and a softmax activation function.\n",
        "- This problem can be solved with only two layers (excluding the Embedding) so try out small architectures first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "cellView": "code",
        "deletable": false,
        "id": "XrE6kpJFfvRY",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: create_model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "def create_model(total_words, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Creates a text generator model\n",
        "\n",
        "    Args:\n",
        "        total_words (int): size of the vocabulary for the Embedding layer input\n",
        "        max_sequence_len (int): length of the input sequences\n",
        "\n",
        "    Returns:\n",
        "        model (tf.keras Model): the text generator model\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    ### START CODE HERE\n",
        "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))  # Embedding layer\n",
        "    model.add(Bidirectional(LSTM(120, return_sequences=True)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(96))\n",
        "    model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "0IpX_Gu_gISk",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87e653c-050a-44ee-81f0-509ad52b0c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "484/484 [==============================] - 18s 22ms/step - loss: 6.9133 - accuracy: 0.0210\n",
            "Epoch 2/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 6.5014 - accuracy: 0.0214\n",
            "Epoch 3/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 6.4075 - accuracy: 0.0249\n",
            "Epoch 4/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 6.2847 - accuracy: 0.0305\n",
            "Epoch 5/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 6.1775 - accuracy: 0.0362\n",
            "Epoch 6/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 6.0946 - accuracy: 0.0395\n",
            "Epoch 7/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 6.0213 - accuracy: 0.0388\n",
            "Epoch 8/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.9396 - accuracy: 0.0440\n",
            "Epoch 9/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 5.8498 - accuracy: 0.0493\n",
            "Epoch 10/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.7562 - accuracy: 0.0523\n",
            "Epoch 11/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 5.6467 - accuracy: 0.0606\n",
            "Epoch 12/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 5.5392 - accuracy: 0.0690\n",
            "Epoch 13/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.4321 - accuracy: 0.0737\n",
            "Epoch 14/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 5.3270 - accuracy: 0.0803\n",
            "Epoch 15/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.2183 - accuracy: 0.0865\n",
            "Epoch 16/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.1115 - accuracy: 0.0993\n",
            "Epoch 17/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 5.0097 - accuracy: 0.1021\n",
            "Epoch 18/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 4.9066 - accuracy: 0.1108\n",
            "Epoch 19/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 4.7998 - accuracy: 0.1211\n",
            "Epoch 20/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 4.7012 - accuracy: 0.1297\n",
            "Epoch 21/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 4.6025 - accuracy: 0.1383\n",
            "Epoch 22/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 4.4920 - accuracy: 0.1443\n",
            "Epoch 23/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 4.3996 - accuracy: 0.1584\n",
            "Epoch 24/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 4.2920 - accuracy: 0.1685\n",
            "Epoch 25/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 4.1934 - accuracy: 0.1812\n",
            "Epoch 26/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 4.0973 - accuracy: 0.1908\n",
            "Epoch 27/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.9966 - accuracy: 0.2079\n",
            "Epoch 28/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 3.8969 - accuracy: 0.2227\n",
            "Epoch 29/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.8110 - accuracy: 0.2374\n",
            "Epoch 30/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 3.7166 - accuracy: 0.2556\n",
            "Epoch 31/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.6245 - accuracy: 0.2723\n",
            "Epoch 32/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.5417 - accuracy: 0.2897\n",
            "Epoch 33/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 3.4480 - accuracy: 0.3101\n",
            "Epoch 34/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.3718 - accuracy: 0.3287\n",
            "Epoch 35/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.2965 - accuracy: 0.3440\n",
            "Epoch 36/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 3.2148 - accuracy: 0.3604\n",
            "Epoch 37/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.1489 - accuracy: 0.3789\n",
            "Epoch 38/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 3.0771 - accuracy: 0.3970\n",
            "Epoch 39/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 3.0073 - accuracy: 0.4128\n",
            "Epoch 40/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.9493 - accuracy: 0.4214\n",
            "Epoch 41/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.8817 - accuracy: 0.4380\n",
            "Epoch 42/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.8148 - accuracy: 0.4508\n",
            "Epoch 43/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.7597 - accuracy: 0.4627\n",
            "Epoch 44/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.6986 - accuracy: 0.4814\n",
            "Epoch 45/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.6429 - accuracy: 0.4899\n",
            "Epoch 46/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.5976 - accuracy: 0.5016\n",
            "Epoch 47/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.5448 - accuracy: 0.5124\n",
            "Epoch 48/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.4829 - accuracy: 0.5279\n",
            "Epoch 49/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.4441 - accuracy: 0.5357\n",
            "Epoch 50/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.3958 - accuracy: 0.5467\n",
            "Epoch 51/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 2.3429 - accuracy: 0.5596\n",
            "Epoch 52/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.3058 - accuracy: 0.5670\n",
            "Epoch 53/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 2.2657 - accuracy: 0.5725\n",
            "Epoch 54/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.2161 - accuracy: 0.5885\n",
            "Epoch 55/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.1863 - accuracy: 0.5973\n",
            "Epoch 56/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.1536 - accuracy: 0.6002\n",
            "Epoch 57/150\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.1032 - accuracy: 0.6149\n",
            "Epoch 58/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.0710 - accuracy: 0.6221\n",
            "Epoch 59/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.0369 - accuracy: 0.6300\n",
            "Epoch 60/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.0178 - accuracy: 0.6275\n",
            "Epoch 61/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.9688 - accuracy: 0.6435\n",
            "Epoch 62/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.9324 - accuracy: 0.6510\n",
            "Epoch 63/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.9120 - accuracy: 0.6516\n",
            "Epoch 64/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.8857 - accuracy: 0.6564\n",
            "Epoch 65/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.8525 - accuracy: 0.6694\n",
            "Epoch 66/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.8101 - accuracy: 0.6762\n",
            "Epoch 67/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 1.7866 - accuracy: 0.6813\n",
            "Epoch 68/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 1.7558 - accuracy: 0.6887\n",
            "Epoch 69/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.7397 - accuracy: 0.6889\n",
            "Epoch 70/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.7059 - accuracy: 0.6987\n",
            "Epoch 71/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.6888 - accuracy: 0.6998\n",
            "Epoch 72/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.6635 - accuracy: 0.7025\n",
            "Epoch 73/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.6519 - accuracy: 0.7077\n",
            "Epoch 74/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.6343 - accuracy: 0.7078\n",
            "Epoch 75/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 1.6006 - accuracy: 0.7199\n",
            "Epoch 76/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.5810 - accuracy: 0.7241\n",
            "Epoch 77/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.5566 - accuracy: 0.7269\n",
            "Epoch 78/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.5345 - accuracy: 0.7307\n",
            "Epoch 79/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.5264 - accuracy: 0.7334\n",
            "Epoch 80/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.5115 - accuracy: 0.7339\n",
            "Epoch 81/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.4863 - accuracy: 0.7390\n",
            "Epoch 82/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.4655 - accuracy: 0.7423\n",
            "Epoch 83/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.4568 - accuracy: 0.7450\n",
            "Epoch 84/150\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 1.4388 - accuracy: 0.7483\n",
            "Epoch 85/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.4197 - accuracy: 0.7537\n",
            "Epoch 86/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.3919 - accuracy: 0.7571\n",
            "Epoch 87/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.3816 - accuracy: 0.7620\n",
            "Epoch 88/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.3690 - accuracy: 0.7640\n",
            "Epoch 89/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.3550 - accuracy: 0.7651\n",
            "Epoch 90/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.3522 - accuracy: 0.7648\n",
            "Epoch 91/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.3453 - accuracy: 0.7652\n",
            "Epoch 92/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.3223 - accuracy: 0.7723\n",
            "Epoch 93/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.3133 - accuracy: 0.7685\n",
            "Epoch 94/150\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 1.2876 - accuracy: 0.7748\n",
            "Epoch 95/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.2773 - accuracy: 0.7795\n",
            "Epoch 96/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.2724 - accuracy: 0.7777\n",
            "Epoch 97/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.2633 - accuracy: 0.7808\n",
            "Epoch 98/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.2640 - accuracy: 0.7778\n",
            "Epoch 99/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 1.2425 - accuracy: 0.7837\n",
            "Epoch 100/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.2274 - accuracy: 0.7840\n",
            "Epoch 101/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.2276 - accuracy: 0.7857\n",
            "Epoch 102/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.2119 - accuracy: 0.7874\n",
            "Epoch 103/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1943 - accuracy: 0.7936\n",
            "Epoch 104/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1916 - accuracy: 0.7947\n",
            "Epoch 105/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.1917 - accuracy: 0.7918\n",
            "Epoch 106/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1648 - accuracy: 0.7963\n",
            "Epoch 107/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 1.1468 - accuracy: 0.8027\n",
            "Epoch 108/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.1509 - accuracy: 0.7979\n",
            "Epoch 109/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1544 - accuracy: 0.7948\n",
            "Epoch 110/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.1440 - accuracy: 0.7979\n",
            "Epoch 111/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1441 - accuracy: 0.7955\n",
            "Epoch 112/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1265 - accuracy: 0.8024\n",
            "Epoch 113/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.1342 - accuracy: 0.7978\n",
            "Epoch 114/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0991 - accuracy: 0.8058\n",
            "Epoch 115/150\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0969 - accuracy: 0.8079\n",
            "Epoch 116/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0838 - accuracy: 0.8111\n",
            "Epoch 117/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0824 - accuracy: 0.8054\n",
            "Epoch 118/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0846 - accuracy: 0.8085\n",
            "Epoch 119/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0894 - accuracy: 0.8045\n",
            "Epoch 120/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0695 - accuracy: 0.8102\n",
            "Epoch 121/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0676 - accuracy: 0.8100\n",
            "Epoch 122/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0542 - accuracy: 0.8123\n",
            "Epoch 123/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 1.0477 - accuracy: 0.8146\n",
            "Epoch 124/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0506 - accuracy: 0.8095\n",
            "Epoch 125/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0384 - accuracy: 0.8165\n",
            "Epoch 126/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0227 - accuracy: 0.8194\n",
            "Epoch 127/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0233 - accuracy: 0.8150\n",
            "Epoch 128/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0230 - accuracy: 0.8148\n",
            "Epoch 129/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0328 - accuracy: 0.8130\n",
            "Epoch 130/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0215 - accuracy: 0.8147\n",
            "Epoch 131/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0111 - accuracy: 0.8168\n",
            "Epoch 132/150\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 1.0040 - accuracy: 0.8179\n",
            "Epoch 133/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9957 - accuracy: 0.8190\n",
            "Epoch 134/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9964 - accuracy: 0.8196\n",
            "Epoch 135/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9822 - accuracy: 0.8237\n",
            "Epoch 136/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9781 - accuracy: 0.8229\n",
            "Epoch 137/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9925 - accuracy: 0.8177\n",
            "Epoch 138/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9801 - accuracy: 0.8220\n",
            "Epoch 139/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9658 - accuracy: 0.8257\n",
            "Epoch 140/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9735 - accuracy: 0.8203\n",
            "Epoch 141/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9794 - accuracy: 0.8170\n",
            "Epoch 142/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9638 - accuracy: 0.8238\n",
            "Epoch 143/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9546 - accuracy: 0.8237\n",
            "Epoch 144/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9487 - accuracy: 0.8252\n",
            "Epoch 145/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9544 - accuracy: 0.8227\n",
            "Epoch 146/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9385 - accuracy: 0.8265\n",
            "Epoch 147/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9436 - accuracy: 0.8263\n",
            "Epoch 148/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9460 - accuracy: 0.8228\n",
            "Epoch 149/150\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9308 - accuracy: 0.8283\n",
            "Epoch 150/150\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9403 - accuracy: 0.8256\n"
          ]
        }
      ],
      "source": [
        "# Get the untrained model\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=150, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy72RPgly55q"
      },
      "source": [
        "**To pass this assignment, your model should achieve a training accuracy of at least 80%**. If your model didn't achieve this threshold, try training again with a different model architecture, consider increasing the number of unit in your `LSTM` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "438194b0-c831-499d-acda-4553a6f57d79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGzCAYAAABzfl4TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCeUlEQVR4nO3dZ3hU1f728XtSSQhJ6BAIRXpXAZWiqESkiGDXPyioxwJRiqAIShMhFBUVFVGP4FEQ9SioHFHpiNKLVKkhdJGWUELqfl6sJwOhpsxkZ2a+n+vaF3v27Ex+C5Dcrr2Kw7IsSwAAAC7gZ3cBAADAexAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAB/RvXt3ValSJU9fO2zYMDkcDtcWlEP5qRtAwSNYADZzOBw5OhYuXGh3qQBwVQ72CgHs9cUXX2R7/Z///Edz5szR559/nu36HXfcobJly+b5+6SlpSkzM1PBwcG5/tr09HSlp6erSJEief7+edW9e3ctXLhQu3fvLvDvDSD3AuwuAPB1Xbt2zfZ62bJlmjNnzkXXL3TmzBmFhobm+PsEBgbmqT5JCggIUEAA/1wAuDoehQAe4NZbb1X9+vW1evVq3XLLLQoNDdWgQYMkSd9//706dOigqKgoBQcHq1q1ahoxYoQyMjKyfcaFYxV2794th8OhN954Qx999JGqVaum4OBgNW3aVCtXrsz2tZcaY+FwOPTcc89p5syZql+/voKDg1WvXj39/PPPF9W/cOFCNWnSREWKFFG1atU0adKkfI3bOH36tPr166fo6GgFBwerVq1aeuONN3RhB+ycOXPUsmVLRUZGKiwsTLVq1XL+vmWZMGGC6tWrp9DQUBUvXlxNmjTRtGnT8lQXAHosAI9x9OhRtWvXTg8//LC6du3qfCwyZcoUhYWF6YUXXlBYWJjmz5+vIUOGKCkpSePGjbvq506bNk0nT57UM888I4fDobFjx+ree+/Vrl27rtrLsWTJEn333Xfq2bOnihUrpnfffVf33Xef9uzZo5IlS0qS1q5dq7Zt26p8+fIaPny4MjIy9Nprr6l06dJ5+n2wLEt33323FixYoCeffFLXXnutfvnlF7344ovav3+/xo8fL0natGmT7rrrLjVs2FCvvfaagoODtWPHDv3+++/Oz/r444/Vq1cv3X///erdu7fOnj2r9evXa/ny5fq///u/PNUH+DwLQKESGxtrXfifZqtWrSxJ1ocffnjR/WfOnLno2jPPPGOFhoZaZ8+edV7r1q2bVblyZefr+Ph4S5JVsmRJ69ixY87r33//vSXJ+vHHH53Xhg4delFNkqygoCBrx44dzmt//vmnJcmaMGGC81rHjh2t0NBQa//+/c5r27dvtwICAi76zEu5sO6ZM2dakqzXX389233333+/5XA4nPWMHz/ekmT9888/l/3sTp06WfXq1btqDQByjkchgIcIDg7W448/ftH1kJAQ5/nJkyd15MgR3XzzzTpz5oz++uuvq37uQw89pOLFiztf33zzzZKkXbt2XfVrY2JiVK1aNefrhg0bKjw83Pm1GRkZmjt3rjp37qyoqCjnfdWrV1e7du2u+vmX8tNPP8nf31+9evXKdr1fv36yLEuzZ8+WJEVGRkoyj4oyMzMv+VmRkZHat2/fRY9+AOQdwQLwEBUqVFBQUNBF1zdt2qR77rlHERERCg8PV+nSpZ0DPxMTE6/6uZUqVcr2OitkHD9+PNdfm/X1WV97+PBhJScnq3r16hfdd6lrOZGQkKCoqCgVK1Ys2/U6deo435dMYGrRooX+9a9/qWzZsnr44Yf19ddfZwsZAwYMUFhYmG644QbVqFFDsbGx2R6VAMg9ggXgIc7vmchy4sQJtWrVSn/++adee+01/fjjj5ozZ47GjBkjSZf9P/Xz+fv7X/K6lYOZ6Pn5WncLCQnR4sWLNXfuXD366KNav369HnroId1xxx3Oga116tTR1q1bNX36dLVs2VLffvutWrZsqaFDh9pcPeC5CBaAB1u4cKGOHj2qKVOmqHfv3rrrrrsUExOT7dGGncqUKaMiRYpox44dF713qWs5UblyZR04cEAnT57Mdj3rsU/lypWd1/z8/NS6dWu99dZb2rx5s0aOHKn58+drwYIFznuKFi2qhx56SJMnT9aePXvUoUMHjRw5UmfPns1TfYCvI1gAHiyrx+D8HoLU1FR98MEHdpWUjb+/v2JiYjRz5kwdOHDAeX3Hjh3OsRC51b59e2VkZOi9997Ldn38+PFyOBzOsRvHjh276GuvvfZaSVJKSookM9PmfEFBQapbt64sy1JaWlqe6gN8HdNNAQ/WvHlzFS9eXN26dVOvXr3kcDj0+eefF4pHEVmGDRumX3/9VS1atFCPHj2coaB+/fpat25drj+vY8eOuu222/TKK69o9+7datSokX799Vd9//336tOnj3Mw6WuvvabFixerQ4cOqly5sg4fPqwPPvhAFStWVMuWLSVJbdq0Ubly5dSiRQuVLVtWW7Zs0XvvvacOHTpcNIYDQM4QLAAPVrJkSc2aNUv9+vXTq6++quLFi6tr165q3bq17rzzTrvLkyQ1btxYs2fPVv/+/TV48GBFR0frtdde05YtW3I0a+VCfn5++uGHHzRkyBB99dVXmjx5sqpUqaJx48apX79+zvvuvvtu7d69W59++qmOHDmiUqVKqVWrVho+fLgiIiIkSc8884ymTp2qt956S6dOnVLFihXVq1cvvfrqqy5rP+Br2CsEgC06d+6sTZs2afv27XaXAsCFGGMBwO2Sk5Ozvd6+fbt++ukn3XrrrfYUBMBt6LEA4Hbly5dX9+7ddc011yghIUETJ05USkqK1q5dqxo1athdHgAXYowFALdr27atvvzySx06dEjBwcFq1qyZRo0aRagAvBA9FgAAwGUYYwEAAFyGYAEAAFymwMdYZGZm6sCBAypWrJgcDkdBf3sAAJAHlmXp5MmTioqKkp/f5fslCjxYHDhwQNHR0QX9bQEAgAvs3btXFStWvOz7BR4sspbJ3bt3r8LDwwv62wMAgDxISkpSdHT0VZe7L/BgkfX4Izw8nGABAICHudowBgZvAgAAlyFYAAAAlyFYAAAAl2FJbwDwAZZlKT09XRkZGXaXgkLK399fAQEB+V4KgmABAF4uNTVVBw8e1JkzZ+wuBYVcaGioypcvr6CgoDx/Rq6CRZUqVZSQkHDR9Z49e+r999/PcxEAAPfIzMxUfHy8/P39FRUVpaCgIBYnxEUsy1Jqaqr++ecfxcfHq0aNGldcBOtKchUsVq5cma0bbePGjbrjjjv0wAMP5OmbAwDcKzU1VZmZmYqOjlZoaKjd5aAQCwkJUWBgoBISEpSamqoiRYrk6XNyFSxKly6d7fXo0aNVrVo1tWrVKk/fHABQMPL6f5/wLa74e5LnMRapqan64osv9MILL1yxWy0lJUUpKSnO10lJSXn9lgAAoJDLczSZOXOmTpw4oe7du1/xvri4OEVERDgP9gkBAMB75TlY/Pvf/1a7du0UFRV1xfsGDhyoxMRE57F37968fksAAPKsSpUqevvtt3N8/8KFC+VwOHTixAm31eSN8hQsEhISNHfuXP3rX/+66r3BwcHOfUHYHwQAcDUOh+OKx7Bhw/L0uStXrtTTTz+d4/ubN2+ugwcPKiIiIk/fL6e8LcDkaYzF5MmTVaZMGXXo0MHV9eSJZUkjRki7dknvvCO5+e8AAMCNDh486Dz/6quvNGTIEG3dutV5LSwszHluWZYyMjIUEHD1H2cXTkC4mqCgIJUrVy5XX4M89FhkZmZq8uTJ6tatW47+IAuCwyF98IH02WfSzp12VwMAhZtlSadPF/xhWTmrr1y5cs4jIiJCDofD+fqvv/5SsWLFNHv2bDVu3FjBwcFasmSJdu7cqU6dOqls2bIKCwtT06ZNNXfu3Gyfe+GjEIfDoU8++UT33HOPQkNDVaNGDf3www/O9y/sSZgyZYoiIyP1yy+/qE6dOgoLC1Pbtm2zBaH09HT16tVLkZGRKlmypAYMGKBu3bqpc+fOef3j0vHjx/XYY4+pePHiCg0NVbt27bR9+3bn+wkJCerYsaOKFy+uokWLql69evrpp5+cX9ulSxeVLl1aISEhqlGjhiZPnpznWnIi18Fi7ty52rNnj5544gl31JNn11xjfo2Pt7cOACjszpyRwsIK/nDlwp8vv/yyRo8erS1btqhhw4Y6deqU2rdvr3nz5mnt2rVq27atOnbsqD179lzxc4YPH64HH3xQ69evV/v27dWlSxcdO3bsCr93Z/TGG2/o888/1+LFi7Vnzx7179/f+f6YMWM0depUTZ48Wb///ruSkpI0c+bMfLW1e/fuWrVqlX744QctXbpUlmWpffv2SktLkyTFxsYqJSVFixcv1oYNGzRmzBhnr87gwYO1efNmzZ49W1u2bNHEiRNVqlSpfNVzVVYBS0xMtCRZiYmJLv3c//s/y5Isa+xYl34sAHi05ORka/PmzVZycrLz2qlT5t/Lgj5Oncp9/ZMnT7YiIiKcrxcsWGBJsmbOnHnVr61Xr541YcIE5+vKlStb48ePd76WZL366qvn/b6csiRZs2fPzva9jh8/7qxFkrVjxw7n17z//vtW2bJlna/Lli1rjRs3zvk6PT3dqlSpktWpU6fL1nnh9znftm3bLEnW77//7rx25MgRKyQkxPr6668ty7KsBg0aWMOGDbvkZ3fs2NF6/PHHL/u9L3Spvy9Zcvrzu3A8y3ABeiwAIGdCQ6VTp+z5vq7SpEmTbK9PnTqlYcOG6X//+58OHjyo9PR0JScnX7XHomHDhs7zokWLKjw8XIcPH77s/aGhoapWrZrzdfny5Z33JyYm6u+//9YNN9zgfN/f31+NGzdWZmZmrtqXZcuWLQoICNCNN97ovFayZEnVqlVLW7ZskST16tVLPXr00K+//qqYmBjdd999znb16NFD9913n9asWaM2bdqoc+fOat68eZ5qySmvWYqtalXz665d9tYBAIWdwyEVLVrwhyu3KClatGi21/3799eMGTM0atQo/fbbb1q3bp0aNGig1NTUK35OYGDgBb83jiuGgEvdb+V08Iib/Otf/9KuXbv06KOPasOGDWrSpIkmTJggSWrXrp0SEhLUt29fHThwQK1bt8726MYdvC5Y0GMBAL7n999/V/fu3XXPPfeoQYMGKleunHbv3l2gNURERKhs2bJauXKl81pGRobWrFmT58+sU6eO0tPTtXz5cue1o0ePauvWrapbt67zWnR0tJ599ll999136tevnz7++GPne6VLl1a3bt30xRdf6O2339ZHH32U53pywusehezeLWVmSiyLDwC+o0aNGvruu+/UsWNHORwODR48OM+PH/Lj+eefV1xcnKpXr67atWtrwoQJOn78eI52lN2wYYOKFSvmfO1wONSoUSN16tRJTz31lCZNmqRixYrp5ZdfVoUKFdSpUydJUp8+fdSuXTvVrFlTx48f14IFC1SnTh1J0pAhQ9S4cWPVq1dPKSkpmjVrlvM9d/GaYFGxohQQIKWmSgcOmNcAAN/w1ltv6YknnlDz5s1VqlQpDRgwwJa9qQYMGKBDhw7psccek7+/v55++mndeeed8vf3v+rX3nLLLdle+/v7Kz09XZMnT1bv3r111113KTU1Vbfccot++ukn52OZjIwMxcbGat++fQoPD1fbtm01fvx4SWYtjoEDB2r37t0KCQnRzTffrOnTp7u+4edxWAX8cCgpKUkRERFKTEx0+Sqc1aubdSwWLZIu+PMBAJ909uxZxcfHq2rVqnneBht5l5mZqTp16ujBBx/UiBEj7C7nqq709yWnP7+96oEB4ywAAHZKSEjQxx9/rG3btmnDhg3q0aOH4uPj9X//9392l1ZgvCpYZI2zYGYIAMAOfn5+mjJlipo2baoWLVpow4YNmjt3rtvHNRQmXjPGQqLHAgBgr+joaP3+++92l2EreiwAAIDLeFWwoMcCAC7N7kWc4Blc8ffEq4JFVo/FgQNScrK9tQBAYZA1JfGMK3cAg9fK+nty4QqjueFVYyxKlJCKFZNOnpQSEqTate2uCADs5e/vr8jISOd+FqGhoTlarAm+xbIsnTlzRocPH1ZkZGSO1t24HK8KFg6H6bX4808zzoJgAQBSuXLlJOmKm2sBkhQZGen8+5JXXhUsJDPO4s8/GWcBAFkcDofKly+vMmXKKC0tze5yUEgFBgbmq6cii9cFC2aGAMCl+fv7u+QHB3AlXjV4U2JmCAAAdvK6YEGPBQAA9vG6YHF+jwXTtgEAKFheFyyqVDG/JiVJx47ZWgoAAD7H64JFSIhUoYI5X7jQ1lIAAPA5XhcsJOmxx8yvAwZIKSn21gIAgC/xymAxcKBUrpy0c6c0YYLd1QAA4Du8MlgUKyaNGmXOR4yQWGwOAICC4ZXBQpK6dZMaNzaDOF991e5qAADwDV4bLPz8pLffNueffCJt3mxrOQAA+ASvDRaS1LKl1LmzWc8iK2QAAAD38epgIUn9+plfP/9cOnLE3loAAPB2Xh8sWrQwYy3OnpUmTbK7GgAAvJvXBwuHQ+rTx5y//76UmmprOQAAeDWvDxaS9OCDUvny0sGD0jff2F0NAADeyyeCRVCQFBtrzsePZ3MyAADcxSeChSQ984xUpIi0erW0aJHd1QAA4J18JliUKiU98YQ5HzbM1lIAAPBaPhMsJOnll81jkUWL2PkUAAB38KlgER0t/etf5nzoUMZaAADgaj4VLCSz82lQkLR4sbRggd3VAADgXXwuWFSsKD31lDkfNoxeCwAAXMnngoVkei2Cg6XffpNmzbK7GgAAvIdPBosKFaTevc15jx5SYqK99QAA4C18MlhIZvBm9erS/v3SgAF2VwMAgHfw2WARGip9/LE5nzSJ6acAALiCzwYLSbr1VrMip2SmoZ45Y2s5AAB4PJ8OFpI0dqyZKbJzp9S3r93VAADg2Xw+WISHS1OmmO3VP/pI+vpruysCAMBz5TpY7N+/X127dlXJkiUVEhKiBg0aaNWqVe6orcC0bm2moEpmjYv4eHvrAQDAU+UqWBw/flwtWrRQYGCgZs+erc2bN+vNN99U8eLF3VVfgRk2TGreXEpKkh5+WEpNtbsiAAA8T0Bubh4zZoyio6M1efJk57WqVau6vCg7BAZK06ZJ114rrVghjRrFLqgAAORWrnosfvjhBzVp0kQPPPCAypQpo+uuu04fZ83ZvIyUlBQlJSVlOwqrypWliRPN+ciR0vr19tYDAICnyVWw2LVrlyZOnKgaNWrol19+UY8ePdSrVy999tlnl/2auLg4RUREOI/o6Oh8F+1ODz0kde4spadLjz8upaXZXREAAJ7DYVk534YrKChITZo00R9//OG81qtXL61cuVJLly695NekpKQoJSXF+TopKUnR0dFKTExUeHh4Pkp3n0OHpLp1pePHTc/FoEF2VwQAgL2SkpIUERFx1Z/fueqxKF++vOrWrZvtWp06dbRnz57Lfk1wcLDCw8OzHYVduXLSO++Y8+HDpS1b7K0HAABPkatg0aJFC23dujXbtW3btqly5couLaow6NpVat/ezA55/nm2VwcAICdyFSz69u2rZcuWadSoUdqxY4emTZumjz76SLGxse6qzzYOhzRhgtlefd48acYMuysCAKDwy1WwaNq0qWbMmKEvv/xS9evX14gRI/T222+rS5cu7qrPVtdcI734ojl/4QUpOdneegAAKOxyNXjTFXI6+KOwOH1aqlNH2rvXrGsxdKjdFQEAUPDcMnjTFxUtKr3xhjkfPVpKSLC3HgAACjOCRQ488IDZYv3sWalfP7urAQCg8CJY5IDDIb37ruTnJ337rRnMCQAALkawyKEGDaSePc15r16syAkAwKUQLHLhtdekkiWlzZulDz6wuxoAAAofgkUuFC9udj2VzOyQw4ftrQcAgMKGYJFLTz4pXX+9lJh4LmQAAACDYJFL/v5m2qkkTZokHTxobz0AABQmBIs8iImRmjUz00/HjrW7GgAACg+CRR44HGYVTkn68EN6LQAAyEKwyKM77qDXAgCACxEs8sjhOLdvyIcfSocO2VsPAACFAcEiH9q0kW66iV4LAACyECzy4cKxFvRaAAB8HcEin9q0kW68UUpOlsaNs7saAADsRbDIp/N7LSZOlP7+29ZyAACwFcHCBe68k14LAAAkgoVLnD9D5IMP6LUAAPgugoWLtG0r3XADvRYAAN9GsHCR88dafPABO58CAHwTwcKF2raVmjal1wIA4LsIFi50fq/F++/TawEA8D0ECxdr1+5cr8Ubb9hdDQAABYtg4WLnzxCh1wIA4GsIFm7Qvr3UpIl05gy9FgAA30KwcAPGWgAAfBXBwk3atzfrWpw5w86nAADfQbBwkwvXtWDnUwCALyBYuFHbtuf2EBkzxu5qAABwP4KFGzkc0vDh5vzDD6WDB+2tBwAAdyNYuFmbNlKzZtLZs9Lo0XZXAwCAexEs3Oz8XotJk6T9++2tBwAAdyJYFICYGKlFCyklhV4LAIB3I1gUgPN7LT76SNq3z956AABwF4JFAbn9dunmm6XUVCkuzu5qAABwD4JFATm/1+KTT6S9e+2tBwAAdyBYFKDbbpNatTK9FqNG2V0NAACuR7AoYFm9Fv/+t5SQYG8tAAC4GsGigLVqZcZbpKXRawEA8D4ECxtk9Vp8+qm0e7etpQAA4FIECxu0bGnWtkhPl0aOtLsaAABch2Bhk6xeiylTpPh4W0sBAMBlCBY2ad7c7COSni699prd1QAA4BoECxuNGGF+/c9/pC1b7K0FAABXIFjY6IYbpM6dpcxMafBgu6sBACD/chUshg0bJofDke2oXbu2u2rzCSNGmFU5v/1WWrXK7moAAMifXPdY1KtXTwcPHnQeS5YscUddPqN+falrV3P+yiv21gIAQH7lOlgEBASoXLlyzqNUqVLuqMunDB8uBQZKv/4qLVxodzUAAORdroPF9u3bFRUVpWuuuUZdunTRnj17rnh/SkqKkpKSsh3IrmpV6amnzPnAgZJl2VsPAAB5latgceONN2rKlCn6+eefNXHiRMXHx+vmm2/WyZMnL/s1cXFxioiIcB7R0dH5LtobvfqqFBIiLVsmzZpldzUAAOSNw7Ly/v/HJ06cUOXKlfXWW2/pySefvOQ9KSkpSklJcb5OSkpSdHS0EhMTFR4entdv7ZUGDpRGj5YaNJDWrZP8mLMDACgkkpKSFBERcdWf3/n60RUZGamaNWtqx44dl70nODhY4eHh2Q5c2ksvSRER0oYN0pdf2l0NAAC5l69gcerUKe3cuVPly5d3VT0+rXhxEy4kacgQswMqAACeJFfBon///lq0aJF2796tP/74Q/fcc4/8/f31yCOPuKs+n9O7t1S2rLRrl/Tvf9tdDQAAuZOrYLFv3z498sgjqlWrlh588EGVLFlSy5YtU+nSpd1Vn88pWvTcehYjR0pnz9pbDwAAuZGvwZt5kdPBH77s7FmpenVp/35pwgTpuefsrggA4OsKZPAm3KNIkXO9FnFx9FoAADwHwaKQeuIJKTpaOnBA+ugju6sBACBnCBaFVHBw9l6L5GR76wEAICcIFoXY449LlStLhw5JEyfaXQ0AAFdHsCjEgoLMUt+SNGqUlJhobz0AAFwNwaKQ695dqlVLOnpUGjPG7moAALgygkUhFxBwLlCMHy/t22dvPQAAXAnBwgPcfbfUsqWZdjp0qN3VAABweQQLD+BwSOPGmfMpU8wmZQAAFEYECw9x003S/fdLmZnSyy/bXQ0AAJdGsPAgo0aZMRc//SQtWGB3NQAAXIxg4UFq1JCeecacv/SS6b0AAKAwIVh4mCFDpLAwadUq6euv7a4GAIDsCBYepkwZacAAcz5okJSSYm89AACcj2Dhgfr2lcqXl+LjWeobAFC4ECw8UNGi0vDh5nz0aDYoAwAUHgQLD9W9u1SlivT339LHH9tdDQAABsHCQwUGnlvPYuxYxloAAAoHgoUH695dqlBB2r9fmjzZ7moAACBYeLTgYLOehWTGWqSl2VsPAAAECw/31FNS2bJSQoL0+ed2VwMA8HUECw8XEiL172/Ohw2TzpyxtRwAgI8jWHiBnj2lSpWkvXulMWPsrgYA4MsIFl4gNFR6801zPnaseSwCAIAdCBZe4r77pFtvlc6ePfdoBACAgkaw8BIOh/TOO5Kfn/Tf/7KtOgDAHgQLL9KwodSjhznv10+yLHvrAQD4HoKFlxk2zGyrvnat9OOPdlcDAPA1BAsvU6qU9Pzz5nzYMHotAAAFi2Dhhfr1O9dr8cMPdlcDAPAlBAsvVLKk1KuXOafXAgBQkAgWXuqFF0yvxbp19FoAAAoOwcJLnd9rMWSIlJFhbz0AAN9AsPBi/fpJkZHS+vXS1Kl2VwMA8AUECy9WooQ0aJA5f/VVsyonAADuRLDwcs8/L0VHmw3KJkywuxoAgLcjWHi5IkWk11835yNHSkeP2lsPAMC7ESx8QJcuUqNGUmKiNGqU3dUAALwZwcIH+PtLY8aY8/fek3bvtrUcAIAXI1j4iDZtpJgYKTXVDOQEAMAdCBY+wuE412sxdaq0Zo299QAAvBPBwodcf70ZbyFJL73EUt8AANcjWPiY11+XgoKkefOkX3+1uxoAgLchWPiYKlWk554z5y+9xFLfAADXIlj4oFdeYalvAIB75CtYjB49Wg6HQ3369HFROSgIFy71nZxsbz0AAO+R52CxcuVKTZo0SQ0bNnRlPSggLPUNAHCHPAWLU6dOqUuXLvr4449VvHhxV9eEAnD+Ut+jRrHUNwDANfIULGJjY9WhQwfFxMRc9d6UlBQlJSVlO1A4dOkiNWzIUt8AANfJdbCYPn261qxZo7i4uBzdHxcXp4iICOcRHR2d6yLhHv7+0tix5pylvgEArpCrYLF371717t1bU6dOVZEiRXL0NQMHDlRiYqLz2Lt3b54KhXuw1DcAwJUclpXz9Rdnzpype+65R/7+/s5rGRkZcjgc8vPzU0pKSrb3LiUpKUkRERFKTExUeHh43iuHy6xZIzVubM5XrzYrdAIAcL6c/vzOVY9F69attWHDBq1bt855NGnSRF26dNG6deuuGipQOLHUNwDAVQJyc3OxYsVUv379bNeKFi2qkiVLXnQdnuX116Vvvjm31Pedd9pdEQDAE7HyJiRlX+q7f38pLc3WcgAAHipXYyxcgTEWhdexY1LNmmZNizFjzGMRAAAkN42xgHcrUUJ6801zPmyYFB9vazkAAA9EsEA2jz0m3Xab2T+kRw8GcgIAcodggWwcDunDD6WgIOmXX6SvvrK7IgCAJyFY4CI1a5qt1SWpTx+JVdgBADlFsMAlDRgg1agh/f03+4gAAHKOYIFLCg6W3nrLnI8fL+3YYW89AADPQLDAZXXoYBbKSk01a1sAAHA1BAtclsNheiv8/aXvv5fmzLG7IgBAYUewwBXVqXNuRc6+faX0dHvrAQAUbgQLXNXQoVLJktKmTdKkSXZXAwAozAgWuKrixc0mZZI0eLBZ8hsAgEshWCBHnnpKathQOn7cLPcNAMClECyQI/7+0ttvm/OJE6WNG20tBwBQSBEskGO33Sbdd5+UkSH17s0+IgCAixEskCvjxklFikjz50v/+Y/d1QAAChuCBXKlalVp+HBz3revdOiQvfUAAAoXggVy7YUXpMaNzUDO2Fi7qwEAFCYEC+RaQID073+bX7/7Tvrvf+2uCABQWBAskCeNGkkDB5rz555ja3UAgEGwQJ698opUs6bZWn3kSLurAQAUBgQL5BlbqwMALkSwQL60b2+2Vk9LY2t1AADBAvnkcJhei6yt1efNs7siAICdCBbIt7p1pZ49zXnv3lJKir31AADsQ7CASwwbJpUqZbZWHzzY7moAAHYhWMAlSpSQPvnEnI8bxyMRAPBVBAu4TKdO0jPPmPNu3aSjR+2tBwBQ8AgWcKk335Rq1ZL27zchgx1QAcC3ECzgUkWLStOmSYGB0rffSp9+andFAICCRLCAy11/vfT66+a8Vy9p2zZ76wEAFByCBdyif3/pttukM2ekLl3MAloAAO9HsIBb+PlJn30mFS8urVplpqMCALwfwQJuEx0tffSROY+Lk5Yts7ceAID7ESzgVvffLz36qJkd8vjj0tmzdlcEAHAnggXc7u23pXLlpL/+koYPt7saAIA7ESzgdiVKSBMnmvNx48yYCwCAdyJYoEB07iw9/LCUkSF1725miwAAvA/BAgVmwgSpTBmzUdmTT7IqJwB4I4IFCkypUtLXX0sBAdL06dKYMXZXBABwNYIFClSrVqbnQpIGDZJ+/NHeegAArkWwQIF79llzWJZZlZMlvwHAexAsYIt33pFuvlk6edKsdcFgTgDwDgQL2CIoSPrqKzOYc8MG6fnn7a4IAOAKBAvYpnx56csvzb4in34qTZlid0UAgPwiWMBWt99+bjXOnj1N7wUAwHPlKlhMnDhRDRs2VHh4uMLDw9WsWTPNnj3bXbXBRwwaJLVtKyUnm/EWSUl2VwQAyKtcBYuKFStq9OjRWr16tVatWqXbb79dnTp10qZNm9xVH3yAn5/0+edSxYpmhshTT7F4FgB4Kodl5e+f8BIlSmjcuHF68sknc3R/UlKSIiIilJiYqPDw8Px8a3iZpUulW26R0tOl996TYmPtrggAkCWnP7/zPMYiIyND06dP1+nTp9WsWbPL3peSkqKkpKRsB3ApzZqZTcokqW9fae5ce+sBAOReroPFhg0bFBYWpuDgYD377LOaMWOG6tate9n74+LiFBER4Tyio6PzVTC8W+/e0kMPSWlpZuOy5cvtrggAkBu5fhSSmpqqPXv2KDExUf/973/1ySefaNGiRZcNFykpKUpJSXG+TkpKUnR0NI9CcFkpKdJdd5keixIlpMWLpXr17K4KAHxbTh+F5HuMRUxMjKpVq6ZJkya5tDD4tlOnpJgY02MRFWV+rVjR7qoAwHe5fYxFlszMzGw9EoArhIVJP/0k1a0rHTgg3XefdPas3VUBAK4mV8Fi4MCBWrx4sXbv3q0NGzZo4MCBWrhwobp06eKu+uDDSpQwu58WLy6tWGEW0GIaKgAUbrkKFocPH9Zjjz2mWrVqqXXr1lq5cqV++eUX3XHHHe6qDz7ummuk6dPNWheTJ0sffGB3RQCAK8n3GIvcYowF8mLcOOmll6SAAGnePLPeBQCg4BTYGAugIPTvLz38sFk864EHpL177a4IAHApBAt4BIdD+uQTqWFD6fBhBnMCQGFFsIDHKFpUmjnTDOpcuVLq0YPBnABQ2BAs4FGqVpW++soM5pwyRRo8mHABAIUJwQIeJyZGmjDBnI8cKY0YYW89AIBzCBbwSD17Sm+8Yc6HDpXi4uytBwBgECzgsfr1OxcoBg2SPvzQ3noAAAQLeLiXX5aGDDHnsbFmpU4AgH0IFvB4w4ZJTz4pZWaaLddXrLC7IgDwXQQLeDyHQ5o4UWrbVkpONluub9tmd1UA4JsIFvAKgYHSN99I118v/fOPdPvt0q5ddlcFAL6HYAGvERYm/fyzVKeOtH+/1Lo1S38DQEEjWMCrlC5tNimrXl3avdv0XCQk2F0VAPgOggW8Tvny0vz5UpUq0o4d0g03SEuX2l0VAPgGggW8UnS09Ntv0rXXmk3LbrtNmjrV7qoAwPsRLOC1KlY04aJzZyklReraVXrrLburAgDvRrCAVwsLk779Vurf37zu108aM8bemgDAmxEs4PX8/KSxY81CWpJZrZONywDAPQgW8AkOh9msbORI83rIEB6LAIA7ECzgUwYNkkaNMuf9+5vHJAAA1yFYwOe8/LLZdt2yzIBOpqICgOsQLOBzHA7pnXfMniJnz0p33y2tWWN3VQDgHQgW8EkBAdL06VLjxtKRI9JNN0lvvml2SAUA5B3BAj6raFHp11+le+6R0tLMmIu2bc0mZgCAvCFYwKeVKGEGcE6aJIWESHPmSC1asDMqAOQVwQI+z+GQnn5aWrVKqlxZ2r5dat5cWrvW7soAwPMQLID/r25d6Y8/pEaNpL//lm65RVq40O6qAMCzECyA80RFSYsWmU3LTp2S2reX5s61uyoA8BwEC+ACERHSTz+ZUJGcLHXsKP3yi91VAYBnIFgAl1CkiPTddyZUZK11MXmyWVQLAHB5BAvgMoKDpf/+10xHTU2VnnjCnB8+bHdlAFB4ESyAKwgKkr75Rho9WgoMlL7/XqpfX/rf/+yuDAAKJ4IFcBX+/tKAAdLKlVKDBmYBrbvukl580fRkAADOIVgAOdSokQkXvXqZ12+8Id18s7Rnj711AUBhQrAAciE42GxgNmOGFBkprVhhVurcssXuygCgcCBYAHnQubNZmbN2bWnfPtNzsWKF3VUBgP0IFkAeVaki/fab1LSpdPSodPvt0mefsUMqAN9GsADyoVQpad48qXVr6fRpqXt3qUkTcw0AfBHBAsinYsXMSp2jR0vh4eYRSUyMeVySkGB3dQBQsAgWgAsEBZkpqTt3mlkjAQFmzYs6daS4OKalAvAdBAvAhUqVMrNG1q0zu6MmJ0uDBklt20onT9pdHQC4H8ECcIN69cyW6//5jxQWJi1YYMZhHD1qd2UA4F4EC8BNHA7p0UdNqChZ0iyu1aqVtHev3ZUBgPsQLAA3a9JEWrxYioqSNm0yvRnvvCOlp9tdGQC4HsECKAB160q//y7ddJMZa9Gnj3TDDSyqBcD7ECyAAlKligkXkyZJxYubaak33ST17CmdOGF3dQDgGrkKFnFxcWratKmKFSumMmXKqHPnztq6dau7agO8jp+f9PTT0l9/SY89JlmWNHGiVKuWNG6cWR4cADxZroLFokWLFBsbq2XLlmnOnDlKS0tTmzZtdPr0aXfVB3ilMmXM8t/z55v9Rg4fll56SapUSbr1VmnRIrsrBIC8cViWZeX1i//55x+VKVNGixYt0i233HLJe1JSUpSSkuJ8nZSUpOjoaCUmJio8PDyv3xrwGqmp0pQp0hdfmL1HJCkw0ExVffhhW0sDAKekpCRFRERc9ed3vsZYJCYmSpJKlChx2Xvi4uIUERHhPKKjo/PzLQGvExRkHo8sXmyWAH/gASktTXrkEendd+2uDgByJ889FpmZmbr77rt14sQJLVmy5LL30WMB5E5mptS7t/Tee+b1889LY8ZIISH21gXAt7m9xyI2NlYbN27U9OnTr3hfcHCwwsPDsx0ALs/Pz/RUvP66eT1hgnTdddLy5fbWBQA5kadg8dxzz2nWrFlasGCBKlas6OqaAJ/ncEivvCL9739S+fLS1q1S8+bSk0+aKat5HxkFAO6Vq2BhWZaee+45zZgxQ/Pnz1fVqlXdVRcASe3bSxs3Sl26mEckn34qtWxppqe+/bZ05ozdFQJAdrkKFrGxsfriiy80bdo0FStWTIcOHdKhQ4eUnJzsrvoAn1eixLkZI926SaGh0vbtUt++UtWq0tix0qlTdlcJAEauBm86HI5LXp88ebK6d++eo8/I6eAPAJd28qQ0bZoZ0Bkfb65FRZn9R+67zzxGAQBXy+nP73ytY5EXBAvANdLSTMB47TVp1y5zrV076f33TU8GALhSgaxjAcA+gYHm0cimTdLQoWY9jNmzpWuvlX780e7qAPgqggXg4YoUkYYNkzZsMDNHkpKku++WhgyRMjLsrg6AryFYAF6iZk1pwQKzoJYkjRghtWghffutlJ5ub20AfAfBAvAiQUFmca3PPzcrdS5fLt1/v1StmlloKy3N7goBeDuCBeCFunaVduyQXn1VKlVK2rNH6tVLatBA+uknu6sD4M0IFoCXiooyj0P27JE++EAqXdqs4Nmhg3TTTdLo0WbgJ6t4AnAlggXg5UJCpB49zKJa/fub2STLl0sDB0r160tNmkgrVthdJQBvQbAAfEREhDRunFlU64MPzHLhwcHSmjWmB6NXLzOjBADyg2AB+JgKFUwPxv/+Zx6TdO1qHodMmGDee+ghafp0s8InAOQWwQLwYWXKmBkkv/4q1ahh9hz5+mvpkUdMyBgwQDp0yO4qAXgSlvQGIMnsnrpqlTRjhln7Yvt2cz04WLr3XrMmxo03So0amXEaAHwLe4UAyLPMTDMtNS5O+uOP7O+Fh0sdO5oNz9q2NYNDAXg/ggWAfLMsaelS86hk+XIze+TYsXPvly4tvfmmGafBrqqAdyNYAHC5zEwTMP77X+mbb6S9e8311q3NTJOaNe2tD4D7sLspAJfz85OaNTO9FDt3mkclRYpI8+ZJtWubgPHZZ8woAXwZwQJAngQGSi+/LG3caNbEsCxp/nype3ez6ucLL0gJCXZXCaCgESwA5Eu1amZNjF27zBLiNWuaaavjx5v3HnpI+u03lg4HfAVjLAC4lGVJv/xiHpfMnXvuer16UrduZiO0mjWlypUlf3/76gSQOwzeBGC7deuk99+Xpk2TzpzJ/l5YmHTbbdKdd5pHKVWr2lIigBwiWAAoNE6ckL74QlqwQNq2zSy+lZKS/Z5OncyYjZtusqVEAFdBsABQaGVkSOvXm0cmP/8sLV58bgzGzTdLzzxjVvtk8S2g8CBYAPAYf/1ldl79/HMpLc1ci4yU7r9fuu46qU4ds8V76dK2lgn4NIIFAI+zb5/0739LkydfPFXV4TC9GQ8/bAIHIQMoWAQLAB4rM9MsujVnjrRlizl27jz3vr+/FBNjQkbnzqZ3A4B7ESwAeJW9e82W7tOnm11YswQHSz16mIGfZcvaVx/g7QgWALzWjh0mYHz5pbR5s7kWGir17Cm1aWPGZZQqZW+NgLchWADwepZlFuF69VWz8+r5oqPNmIxWraRbb5Vq1GAHViA/CBYAfIZlSbNmmVkla9eaHo0LlStnQkbLllKZMmaBrogIqVIls7cJq4ACV0awAOCzkpLMOIxFi8yxbNnFC3KdLzBQuuYa6YEHpGeflSpUKLhaAU9BsACA/+/sWfOoZOFCafVqKTHRbO1+7JiZ4pqefu7egADpnnvMcuP16pmjZEnbSgcKDYIFAORAerq0f7/p1Xj/fbMT64XatpUGDTJjNgBfRbAAgDxYt87MONmwwcw42b373HstW5o9Ta67Trr2Wnoy4FsIFgDgAjt3SmPHSlOmSKmp2d8rWtQMCi1Xzsw6qVfPLD8eGnru8UrjxlKJEgVeNuByBAsAcKH9+6X//MeM0Vi7Vtq1K2dfFxxsBoU+/bTp8WDKKzwVwQIA3OjUKenQIXPs3282Utu0Sdq61fRWBARIp09nX4q8QgXpzjvNUaGCmSbrcEi1a/NYBYUfwQIAbGZZZtrrRx+ZVUJPn770ff7+58ZvdOpkpr4ChQ3BAgAKkeRkM+Pk55+l+fNNj4fDYbaJv3An1/r1zeZqDRuahbyKFTNrbWT9a127NhuvoeARLADAQ8THSz/8IH3/vbR4sZSRceX7ixaVnn9e6tePPVFQcAgWAOCBjh2TfvpJ+t//pAMHzEJeJ0+eCxvJyWZch2QCxhNPSA89JDVrJvn5Zf+s1FTp+HFzX1hYwbYD3odgAQBeKGtflGHDpDVrzl2vUEGqWdMEiWPHzHHqlHnP4ZCqV5euv95szpb1r37FiuaRS5UqBdwIeCSCBQB4McuSfv1VmjrVPEJJSrr0fQ7HuSBxOU2amHEbO3dK27dLZctK48dLd9zh+rrhuQgWAOAjzp41A0ITE81iXOcfERHS0aNm7Y01a6QjR86tpbFqlRnTkZl56c99/HHpzTel4sULri0ovAgWAICr+vtvM3D0yBHzuOSaa6TPPpPee+9cT0eRImY10fLlzbTYW24xS5qHhJgFwPz8zFTa06dNuPn7b+nwYTONtlMnszIpPB/BAgCQZ0uWmNVCt2zJ3+f4+5sFwe691/SghIaaXxs1koKCXFMrCgbBAgCQL5Yl/fOPmYly+rS0Y4e0aJE5du6UUlLMYVkmMBQtatbcKFvWHAcOSMuXX/qzQ0KkFi3MUa2aVKmSVKaMdOaMmQWTmWl6RdhnpfBwW7BYvHixxo0bp9WrV+vgwYOaMWOGOnfu7PLCAACeIWtp8kvZts3ssbJsmQkNycnS3r1m3EdO1K4tNW9uej3atLnywmCZmWY32vh4sylcdDR7s7hSTn9+B+T2g0+fPq1GjRrpiSee0L333puvIgEAnu9KP7xr1pRefz37tcxM84hl4UKzqVtCgjmOHDHrbYSHmzU4du40e7D89Zf06afmsUrTpuYeyzp3SCa0bN5sejuylCplZrxkHY0bm2m5hA33ytejEIfDQY8FAMAtjhwxPR0LFkizZ+dsvEdQkHmssnv3ua3rzxcWZgap1qhhjurVzaOYwMBzi5DVq8dMmEtxW49FbqWkpCglJSVbYQAAXE2pUtJdd5njzTfNVvUrVpgej6xeB4fDHAEBUq1a5ggMNFNw1683PSKrVplfN240i4atW2eOy/HzM4uJ3X67CR6lSplAsnKlNHeu9McfZobMrbdKrVqZXy+1yFhqqnnss2ePeSxTvbrLf4sKJbf3WAwbNkzDhw+/6Do9FgCAgpSSYnoytm/PfuzebcKKv78JAxduCpcTlSqZabgOhxnjsXu3tH9/9sXJatSQ2reXbr7Z9IpUr24CkacokFkhOQkWl+qxiI6OJlgAAAql/fvNgmO//SYdPGgGmh4/LtWpI8XEmACxb58ZI7JokekRudRjF8nMfqlY0YSNC+8JCpKqVjW9GRUrmp1u9+83s2nKlDEh5K67TGg5dMgcx4+bGTqnTpmZN7ffbsakZDl71szeqV/f9b8vhSZY5LUwAAA8walT5vHI0qVmMbEqVcxRtapUurTpxUhKMo9Rfv7ZPIbZtMkMOM2vgAAza6ZMGWnDBtMDY1lmEGvRovn//PMVmjEWAAB4s7AwMxW2TZvL3xMebhYJy5pMmTU1NiHBjMPYt8+MDalQwYzf+Osvs8PtvHmmF6JYMbOCaYkS5vsVLWru2bbNLMt+vpIlzWfWru22Jl9RroPFqVOntGPHDufr+Ph4rVu3TiVKlFClSpVcWhwAAN7Iz88sn37NNZd+/7bbpB49zLiQ9PTL9z7s2mU2ozt92jz+aNjQBBA7p9Tm+lHIwoULddttt110vVu3bpoyZcpVv55HIQAAeB63PQq59dZbVcCrgAMAAA/hZ3cBAADAexAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAyxAsAACAy+R6E7L8ytrALCkpqaC/NQAAyKOsn9tX24i0wIPFyZMnJUnR0dEF/a0BAEA+nTx5UhEREZd932EV8B7omZmZOnDggIoVKyaHw+Gyz01KSlJ0dLT27t17xX3ivYmvtdnX2iv5Xpt9rb2S77XZ19oreU+bLcvSyZMnFRUVJT+/y4+kKPAeCz8/P1WsWNFtnx8eHu7Rf3B54Wtt9rX2Sr7XZl9rr+R7bfa19kre0eYr9VRkYfAmAABwGYIFAABwGa8JFsHBwRo6dKiCg4PtLqXA+Fqbfa29ku+12dfaK/lem32tvZLvtbnAB28CAADv5TU9FgAAwH4ECwAA4DIECwAA4DIECwAA4DIECwAA4DJeEyzef/99ValSRUWKFNGNN96oFStW2F2SS8TFxalp06YqVqyYypQpo86dO2vr1q3Z7jl79qxiY2NVsmRJhYWF6b777tPff/9tU8WuNXr0aDkcDvXp08d5zRvbu3//fnXt2lUlS5ZUSEiIGjRooFWrVjnftyxLQ4YMUfny5RUSEqKYmBht377dxorzLiMjQ4MHD1bVqlUVEhKiatWqacSIEdk2NvL09i5evFgdO3ZUVFSUHA6HZs6cme39nLTv2LFj6tKli8LDwxUZGaknn3xSp06dKsBW5M6V2pyWlqYBAwaoQYMGKlq0qKKiovTYY4/pwIED2T7Dk9p8tT/j8z377LNyOBx6++23s133pPbmhlcEi6+++kovvPCChg4dqjVr1qhRo0a68847dfjwYbtLy7dFixYpNjZWy5Yt05w5c5SWlqY2bdro9OnTznv69u2rH3/8Ud98840WLVqkAwcO6N5777WxatdYuXKlJk2apIYNG2a77m3tPX78uFq0aKHAwEDNnj1bmzdv1ptvvqnixYs77xk7dqzeffddffjhh1q+fLmKFi2qO++8U2fPnrWx8rwZM2aMJk6cqPfee09btmzRmDFjNHbsWE2YMMF5j6e39/Tp02rUqJHef//9S76fk/Z16dJFmzZt0pw5czRr1iwtXrxYTz/9dEE1Ideu1OYzZ85ozZo1Gjx4sNasWaPvvvtOW7du1d13353tPk9q89X+jLPMmDFDy5YtU1RU1EXveVJ7c8XyAjfccIMVGxvrfJ2RkWFFRUVZcXFxNlblHocPH7YkWYsWLbIsy7JOnDhhBQYGWt98843zni1btliSrKVLl9pVZr6dPHnSqlGjhjVnzhyrVatWVu/evS3L8s72DhgwwGrZsuVl38/MzLTKlStnjRs3znntxIkTVnBwsPXll18WRIku1aFDB+uJJ57Idu3ee++1unTpYlmW97VXkjVjxgzn65y0b/PmzZYka+XKlc57Zs+ebTkcDmv//v0FVnteXdjmS1mxYoUlyUpISLAsy7PbfLn27tu3z6pQoYK1ceNGq3Llytb48eOd73lye6/G43ssUlNTtXr1asXExDiv+fn5KSYmRkuXLrWxMvdITEyUJJUoUUKStHr1aqWlpWVrf+3atVWpUiWPbn9sbKw6dOiQrV2Sd7b3hx9+UJMmTfTAAw+oTJkyuu666/Txxx8734+Pj9ehQ4eytTkiIkI33nijR7a5efPmmjdvnrZt2yZJ+vPPP7VkyRK1a9dOkve190I5ad/SpUsVGRmpJk2aOO+JiYmRn5+fli9fXuA1u0NiYqIcDociIyMleV+bMzMz9eijj+rFF19UvXr1Lnrf29p7vgLf3dTVjhw5ooyMDJUtWzbb9bJly+qvv/6yqSr3yMzMVJ8+fdSiRQvVr19fknTo0CEFBQU5/+PMUrZsWR06dMiGKvNv+vTpWrNmjVauXHnRe97Y3l27dmnixIl64YUXNGjQIK1cuVK9evVSUFCQunXr5mzXpf6Oe2KbX375ZSUlJal27dry9/dXRkaGRo4cqS5dukiS17X3Qjlp36FDh1SmTJls7wcEBKhEiRJe8Xtw9uxZDRgwQI888ohzt09va/OYMWMUEBCgXr16XfJ9b2vv+Tw+WPiS2NhYbdy4UUuWLLG7FLfZu3evevfurTlz5qhIkSJ2l1MgMjMz1aRJE40aNUqSdN1112njxo368MMP1a1bN5urc72vv/5aU6dO1bRp01SvXj2tW7dOffr0UVRUlFe2F9mlpaXpwQcflGVZmjhxot3luMXq1av1zjvvaM2aNXI4HHaXU+A8/lFIqVKl5O/vf9GsgL///lvlypWzqSrXe+655zRr1iwtWLBAFStWdF4vV66cUlNTdeLEiWz3e2r7V69ercOHD+v6669XQECAAgICtGjRIr377rsKCAhQ2bJlvaq9klS+fHnVrVs327U6depoz549kuRsl7f8HX/xxRf18ssv6+GHH1aDBg306KOPqm/fvoqLi5Pkfe29UE7aV65cuYsGn6enp+vYsWMe/XuQFSoSEhI0Z84cZ2+F5F1t/u2333T48GFVqlTJ+e9YQkKC+vXrpypVqkjyrvZeyOODRVBQkBo3bqx58+Y5r2VmZmrevHlq1qyZjZW5hmVZeu655zRjxgzNnz9fVatWzfZ+48aNFRgYmK39W7du1Z49ezyy/a1bt9aGDRu0bt0659GkSRN16dLFee5N7ZWkFi1aXDSFeNu2bapcubIkqWrVqipXrly2NiclJWn58uUe2eYzZ87Izy/7Pz3+/v7KzMyU5H3tvVBO2tesWTOdOHFCq1evdt4zf/58ZWZm6sYbbyzwml0hK1Rs375dc+fOVcmSJbO9701tfvTRR7V+/fps/45FRUXpxRdf1C+//CLJu9p7EbtHj7rC9OnTreDgYGvKlCnW5s2braefftqKjIy0Dh06ZHdp+dajRw8rIiLCWrhwoXXw4EHncebMGec9zz77rFWpUiVr/vz51qpVq6xmzZpZzZo1s7Fq1zp/VohleV97V6xYYQUEBFgjR460tm/fbk2dOtUKDQ21vvjiC+c9o0ePtiIjI63vv//eWr9+vdWpUyeratWqVnJyso2V5023bt2sChUqWLNmzbLi4+Ot7777zipVqpT10ksvOe/x9PaePHnSWrt2rbV27VpLkvXWW29Za9eudc6AyEn72rZta1133XXW8uXLrSVLllg1atSwHnnkEbuadFVXanNqaqp19913WxUrVrTWrVuX7d+ylJQU52d4Upuv9md8oQtnhViWZ7U3N7wiWFiWZU2YMMGqVKmSFRQUZN1www3WsmXL7C7JJSRd8pg8ebLznuTkZKtnz55W8eLFrdDQUOuee+6xDh48aF/RLnZhsPDG9v74449W/fr1reDgYKt27drWRx99lO39zMxMa/DgwVbZsmWt4OBgq3Xr1tbWrVttqjZ/kpKSrN69e1uVKlWyihQpYl1zzTXWK6+8ku0HjKe3d8GCBZf877Zbt26WZeWsfUePHrUeeeQRKywszAoPD7cef/xx6+TJkza0Jmeu1Ob4+PjL/lu2YMEC52d4Upuv9md8oUsFC09qb244LOu85e4AAADywePHWAAAgMKDYAEAAFyGYAEAAFyGYAEAAFyGYAEAAFyGYAEAAFyGYAEAAFyGYAEAAFyGYAEAAFyGYAEAAFyGYAEAAFzm/wFgHg8v/T5GYAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Take a look at the training curves of your model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjvED5A3qrn2"
      },
      "source": [
        "Before closing the assignment, be sure to also download the `history.pkl` file which contains the information of the training history of your model and will be used to compute your grade. You can download this file by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "9QRG73l6qE-c",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "189be92c-b638-49bf-f8fa-09d8ab16f1c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d82b2209-fea7-4cea-98be-ca56817eb975\", \"history.pkl\", 2742)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdsMszk9zBs_"
      },
      "source": [
        "## See your model in action\n",
        "\n",
        "After all your work it is finally time to see your model generating text.\n",
        "\n",
        "Run the cell below to generate the next 100 words of a seed text.\n",
        "\n",
        "After submitting your assignment you are encouraged to try out training for different amounts of epochs and seeing how this affects the coherency of the generated text. Also try changing the seed text to see what you get!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ce391f-9743-4779-ce3b-c431516b3c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope is telling show thee words good 'will ' live in day of mine own desert sight care with pleasure blood be self prone indigest refined pen rage age brings grow good part hate die thence near say bright mind bright days live cured words ' do not new bright so blind age fire mine eye alone shine thee such foes strive to thee hence strife about rolling state forth disgrace her bevel end dead minds on memory pride face aside shown survey doom thy granting state of thine deem'd rare shade remain remain another mind worth new shade back bright\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # Convert the text into sequences\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    # Pad the sequences\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    # Get the probabilities of predicting a word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    # Choose the next word based on the maximum probability\n",
        "    predicted = np.argmax(predicted, axis=-1).item()\n",
        "    # Get the actual word from the word index\n",
        "    output_word = tokenizer.index_word[predicted]\n",
        "    # Append to the current text\n",
        "    seed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQVDbdcYqSux"
      },
      "source": [
        "## Download your notebook for grading\n",
        "\n",
        "Along with the `history.pkl` file earlier, you will also need to submit your solution notebook for grading. The following code cells will check if this notebook's grader metadata (i.e. hidden data in the notebook needed for grading) is not modified by your workspace. This will ensure that the autograder can evaluate your code properly. Depending on its output, you will either:\n",
        "\n",
        "* *if the metadata is intact*: Download the current notebook. Click on the File tab on the upper left corner of the screen then click on `Download -> Download .ipynb.` You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file.\n",
        "<br>\n",
        "\n",
        "* *if the metadata is missing*: A new notebook with your solutions will be created on this Colab workspace. It should be downloaded automatically and you can submit that to the grader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ZUEiIXZEShHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1c6f2e-8018-4575-fe1b-c41df20b8a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-17 20:30:36--  https://storage.googleapis.com/tensorflow-1-public/colab_metadata_checker.py\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 173.194.203.128, 74.125.199.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1997 (2.0K) [text/x-python-script]\n",
            "Saving to: colab_metadata_checker.py\n",
            "\n",
            "\r          colab_met   0%[                    ]       0  --.-KB/s               \rcolab_metadata_chec 100%[===================>]   1.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-17 20:30:36 (48.4 MB/s) - colab_metadata_checker.py saved [1997/1997]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download metadata checker\n",
        "!wget -nc https://storage.googleapis.com/tensorflow-1-public/colab_metadata_checker.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Ek87UXX7Sj6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c3c825-c339-490c-bbea-d5a0082afcc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grader metadata detected! You can download this notebook by clicking `File > Download > Download as .ipynb` and submit it to the grader!\n"
          ]
        }
      ],
      "source": [
        "import colab_metadata_checker\n",
        "\n",
        "# Please see the output of this cell to see which file you need to submit to the grader\n",
        "colab_metadata_checker.run('C3W4_Assignment_fixed.ipynb')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8r7-87s59Ng"
      },
      "source": [
        "**Please disregard the following note if the notebook metadata is detected**\n",
        "\n",
        "_Note: Just in case the automatic download fails when the metadata is missing, you can also do these steps:_\n",
        "* _Click the Folder icon on the left side of this screen to open the File Manager._\n",
        "* _Click the Folder Refresh icon in the File Manager to see the latest files in the workspace. You should see a file ending with a `_fixed.ipynb`._\n",
        "* _Right-click on that file to save locally and submit it to the grader._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r-X-HXtSc8N"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a neural network capable of predicting the next word in a sequence of text!\n",
        "\n",
        "**We hope to see you in the next course of the specialization! Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "dlai_version": "1.2.0",
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}